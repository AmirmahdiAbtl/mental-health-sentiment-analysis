{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf17ff6b",
   "metadata": {},
   "source": [
    "# Testing GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb33cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb3d95d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df4c4939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs available:  1\n",
      "GPU Name:  PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# List all physical GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"GPUs available: \", len(gpus))\n",
    "    for gpu in gpus:\n",
    "        print(\"GPU Name: \", gpu)\n",
    "else:\n",
    "    print(\"No GPUs available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc998e2d",
   "metadata": {},
   "source": [
    "# Loading Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8660869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense, Embedding, Dropout, InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ea098a",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "191feafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>statement</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          statement   status\n",
       "0           0                                         oh my gosh  Anxiety\n",
       "1           1  trouble sleeping, confused mind, restless hear...  Anxiety\n",
       "2           2  All wrong, back off dear, forward doubt. Stay ...  Anxiety\n",
       "3           3  I've shifted my focus to something else but I'...  Anxiety\n",
       "4           4  I'm restless and restless, it's been a month n...  Anxiety"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Combined Data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b07c3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "adhd                    33392\n",
       "Normal                  32702\n",
       "Depression              30808\n",
       "addiction                8198\n",
       "Anxiety                  7776\n",
       "Stress                   5338\n",
       "Personality disorder     2402\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[~df[\"status\"].isin([\"Suicidal\", \"Bipolar\"])]\n",
    "df[\"status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "272bf6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_addiction = pd.read_csv(\"addiction_pre_features_tfidf_256.csv\")\n",
    "df_adhd = pd.read_csv(\"adhd_pre_features_tfidf_256.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c42b8c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Unnamed: 0\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "394dfca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lonely = df_lonely[[\"post\", \"subreddit\"]]\n",
    "df_adhd = df_adhd[[\"post\", \"subreddit\"]]\n",
    "df_addiction = df_addiction[[\"post\", \"subreddit\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79fa8606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lonely.rename(columns = {'subreddit':'status', \"post\" : \"statement\"}, inplace = True)\n",
    "df_adhd.rename(columns = {'subreddit':'status', \"post\" : \"statement\"}, inplace = True)\n",
    "df_addiction.rename(columns = {'subreddit':'status', \"post\" : \"statement\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab813d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df, df_addiction, df_adhd])\n",
    "\n",
    "# Resetting index for the combined DataFrame\n",
    "df_combined.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d54e56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "adhd                    16696\n",
       "Normal                  16351\n",
       "Depression              15404\n",
       "addiction                4099\n",
       "Anxiety                  3888\n",
       "Stress                   2669\n",
       "Personality disorder     1201\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined[\"status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f787b4b7",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a833c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    text = str(text)\n",
    "    \n",
    "    # Remove retweet \"RT\" text\n",
    "    text = re.sub(r'^RT[\\s]+', '', text)\n",
    "    \n",
    "    # Remove HTML line breaks\n",
    "    text = re.sub(r'<br />', '', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Remove single quotes\n",
    "    text = text.replace(\"\\'\", \"\")\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Get stopwords and initialize stemmer\n",
    "    stopwords_english = stopwords.words(\"english\")\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    cleaned_words = []\n",
    "\n",
    "    for x in tokens:\n",
    "        if x not in stopwords_english:\n",
    "            stem_word = stemmer.stem(x)\n",
    "            cleaned_words.append(stem_word)\n",
    "    \n",
    "    return ' '.join(cleaned_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14a2f3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_text(text):\n",
    "    try:\n",
    "        blob = TextBlob(text)\n",
    "        translated = blob.translate(to='fr').translate(to='en')\n",
    "        return str(translated)\n",
    "    except Exception as e:\n",
    "        return text\n",
    "\n",
    "df_combined['augmented_statement'] = df_combined['statement'].apply(augment_text)\n",
    "augmented_df = df_combined[['statement', 'status']].copy()\n",
    "augmented_df['statement'] = df_combined['augmented_statement']\n",
    "df = pd.concat([df_combined, augmented_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23923a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "adhd                    33392\n",
       "Normal                  32702\n",
       "Depression              30808\n",
       "addiction                8198\n",
       "Anxiety                  7776\n",
       "Stress                   5338\n",
       "Personality disorder     2402\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "159f7f59",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aug_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m df_new \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPersonality disorder\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m \u001b[43maug_df\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatement\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatement\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(augment_text)\n\u001b[0;32m      3\u001b[0m aug_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      4\u001b[0m aug_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'aug_df' is not defined"
     ]
    }
   ],
   "source": [
    "df_new = df[df['status'] == \"Personality disorder\"]\n",
    "aug_df[\"statement\"] = df_new[\"statement\"].apply(augment_text)\n",
    "aug_df[\"status\"] = df_new[\"status\"]\n",
    "aug_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6c5d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cleaned_post\"] = df[\"statement\"].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c3989dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_post'] = df['cleaned_post'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc12393",
   "metadata": {},
   "source": [
    "# Data Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd4b7714",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['cleaned_post']\n",
    "y = df['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7fb70f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69bd9f3",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2222d9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.Series(X_train).fillna(\"\").astype(str).tolist()\n",
    "X_test = pd.Series(X_test).fillna(\"\").astype(str).tolist()\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 5000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "train_x_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "test_x_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "max_length = 100\n",
    "train_x_padded = pad_sequences(train_x_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "test_x_padded = pad_sequences(test_x_sequences, maxlen=max_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2554e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the tokenizer\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d9b7e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_json = tokenizer.to_json()\n",
    "with open('tokenizer.json', 'w') as json_file:\n",
    "    json_file.write(tokenizer_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c789e072",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "329fad1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 100, 64)           320000    \n",
      "                                                                 \n",
      " bidirectional_21 (Bidirecti  (None, 100, 128)         66048     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " bidirectional_22 (Bidirecti  (None, 128)              98816     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 9)                 585       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 494,217\n",
      "Trainable params: 493,961\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=64, input_length=max_length),\n",
    "    \n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    Dropout(0.6),  # Increase dropout to prevent overfitting\n",
    "    \n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dropout(0.6),\n",
    "    \n",
    "    BatchNormalization(),  # Adding Batch Normalization for better generalization\n",
    "    \n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),  # Adding L2 regularization\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(7, activation='softmax')  # Use softmax for multi-class classification\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "2a62c097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Anxiety': 0, 'Depression': 1, 'Normal': 2, 'Personality disorder': 3, 'Stress': 4, 'addiction': 5, 'adhd': 6}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labels = ['adhd', 'Normal', 'Depression', 'addiction', 'Anxiety', 'Stress', 'Personality disorder']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "train_y_encoded = label_encoder.fit_transform(y_train)\n",
    "test_y_encoded = label_encoder.transform(y_test)\n",
    "label_mapping = dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))\n",
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc6a4291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b55ea30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "Normal                  32702\n",
       "Depression              30808\n",
       "addiction                8198\n",
       "Anxiety                  7776\n",
       "Bipolar                  5754\n",
       "Stress                   5338\n",
       "Personality disorder     2402\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a27906da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2.1356310013717423, 1: 2.886108214575368, 2: 0.5390374794425691, 3: 0.5078180743277679, 4: 6.91368304190952, 5: 3.1110278506306983, 6: 2.0256973245507033, 7: 0.4973247085130171, 8: 0.7192146672441172}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class_counts = np.array([7776, 5754, 30808, 32702, 2402, 5338, 8198])\n",
    "total_samples = np.sum(class_counts)\n",
    "num_classes = len(class_counts)\n",
    "class_weights = {i: total_samples / (num_classes * count) for i, count in enumerate(class_counts)}\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "aab40d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "934/935 [============================>.] - ETA: 0s - loss: 1.4488 - accuracy: 0.6322\n",
      "Epoch 1: val_accuracy did not improve from 0.89827\n",
      "935/935 [==============================] - 63s 63ms/step - loss: 1.4489 - accuracy: 0.6322 - val_loss: 0.8660 - val_accuracy: 0.7692 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "934/935 [============================>.] - ETA: 0s - loss: 0.8386 - accuracy: 0.7969\n",
      "Epoch 2: val_accuracy did not improve from 0.89827\n",
      "935/935 [==============================] - 55s 59ms/step - loss: 0.8386 - accuracy: 0.7969 - val_loss: 0.6470 - val_accuracy: 0.8266 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "934/935 [============================>.] - ETA: 0s - loss: 0.6814 - accuracy: 0.8344\n",
      "Epoch 3: val_accuracy did not improve from 0.89827\n",
      "935/935 [==============================] - 54s 57ms/step - loss: 0.6814 - accuracy: 0.8344 - val_loss: 0.6204 - val_accuracy: 0.8357 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "934/935 [============================>.] - ETA: 0s - loss: 0.6051 - accuracy: 0.8512\n",
      "Epoch 4: val_accuracy did not improve from 0.89827\n",
      "935/935 [==============================] - 54s 57ms/step - loss: 0.6053 - accuracy: 0.8512 - val_loss: 0.5617 - val_accuracy: 0.8517 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "934/935 [============================>.] - ETA: 0s - loss: 0.5553 - accuracy: 0.8612\n",
      "Epoch 5: val_accuracy did not improve from 0.89827\n",
      "935/935 [==============================] - 54s 58ms/step - loss: 0.5555 - accuracy: 0.8612 - val_loss: 0.7635 - val_accuracy: 0.7834 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "934/935 [============================>.] - ETA: 0s - loss: 0.5334 - accuracy: 0.8660\n",
      "Epoch 6: val_accuracy did not improve from 0.89827\n",
      "935/935 [==============================] - 54s 58ms/step - loss: 0.5334 - accuracy: 0.8661 - val_loss: 0.5321 - val_accuracy: 0.8627 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "934/935 [============================>.] - ETA: 0s - loss: 0.4584 - accuracy: 0.8847\n",
      "Epoch 7: val_accuracy did not improve from 0.89827\n",
      "935/935 [==============================] - 54s 58ms/step - loss: 0.4584 - accuracy: 0.8847 - val_loss: 0.5309 - val_accuracy: 0.8665 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "934/935 [============================>.] - ETA: 0s - loss: 0.4600 - accuracy: 0.8810\n",
      "Epoch 8: val_accuracy did not improve from 0.89827\n",
      "935/935 [==============================] - 54s 57ms/step - loss: 0.4600 - accuracy: 0.8810 - val_loss: 0.4908 - val_accuracy: 0.8757 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "934/935 [============================>.] - ETA: 0s - loss: 0.4040 - accuracy: 0.8965\n",
      "Epoch 9: val_accuracy did not improve from 0.89827\n",
      "935/935 [==============================] - 53s 57ms/step - loss: 0.4040 - accuracy: 0.8965 - val_loss: 0.4948 - val_accuracy: 0.8812 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "934/935 [============================>.] - ETA: 0s - loss: 0.3741 - accuracy: 0.9043\n",
      "Epoch 10: val_accuracy did not improve from 0.89827\n",
      "935/935 [==============================] - 53s 57ms/step - loss: 0.3742 - accuracy: 0.9042 - val_loss: 0.4449 - val_accuracy: 0.8936 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x_padded,\n",
    "                           train_y_encoded,\n",
    "                           epochs=10,\n",
    "                           batch_size=128,\n",
    "                           validation_data=(test_x_padded, test_y_encoded),\n",
    "                           class_weight=class_weights,\n",
    "                           callbacks=[early_stopping, model_checkpoint, reduce_lr]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8f43b3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Personality disorder'], dtype=object)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [df[df[\"status\"] == \"Personality disorder\"].iloc[88][\"cleaned_post\"]]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_text)\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "predictions = model.predict(sample_padded)\n",
    "label_encoder.inverse_transform([np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4362b793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Bipolar'], dtype=object)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [\"Every day feels like a battle with an invisible enemy. My thoughts race, my heart pounds, and I can't seem to find peace, no matter how hard I try. Simple tasks feel overwhelming, and I constantly worry about things that might never happen. It's exhausting, and I long for calm.\"]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_text)\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "predictions = model.predict(sample_padded)\n",
    "label_encoder.inverse_transform([np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "328910bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Bipolar'], dtype=object)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [\"My moods shift like the changing seasons, from highs where I feel unstoppable, full of ideas and energy, to lows where even getting out of bed feels impossible. It's confusing and tiring, not knowing which version of me will wake up each day. I just want stability.\"]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_text)\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "predictions = model.predict(sample_padded)\n",
    "label_encoder.inverse_transform([np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9507d5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['addiction'], dtype=object)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [\"It's like a heavy fog has settled over my life, dulling everything. I feel disconnected from the world, and nothing seems to bring joy anymore. Even the things I used to love don't matter now. It's hard to find the motivation to do anything, even the basics.\"]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_text)\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "predictions = model.predict(sample_padded)\n",
    "label_encoder.inverse_transform([np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7aacfea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Stress'], dtype=object)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [\"Life has its ups and downs, but overall, things feel manageable. I have my moments of stress and sadness, but I also find joy and fulfillment in the little things. I try to stay balanced, focusing on the positive and working through challenges as they come\"]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_text)\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "predictions = model.predict(sample_padded)\n",
    "label_encoder.inverse_transform([np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ba633840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['adhd'], dtype=object)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [\"I often feel like I'm wearing a mask, unsure of who I really am. My relationships are complicated, and sometimes, I react in ways that even I don't understand. It's like I'm constantly trying to figure out how to fit in, but never quite finding my place.\"]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_text)\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "predictions = model.predict(sample_padded)\n",
    "label_encoder.inverse_transform([np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "cc13adf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['adhd'], dtype=object)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [\"The pressure never seems to let up. There's always something that needs to be done, and I feel like I'm constantly racing against the clock. My mind is always on, juggling responsibilities, and it’s hard to relax. Sometimes, I wish I could just pause everything.\"]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_text)\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "predictions = model.predict(sample_padded)\n",
    "label_encoder.inverse_transform([np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "601061b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['addiction'], dtype=object)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [\"It started out as something small, just a way to cope, but now it feels like it has taken over my life. I crave it even when I don't want to, and it's affecting everything—my relationships, my work, my health. I wish I could break free.\"]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_text)\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "predictions = model.predict(sample_padded)\n",
    "label_encoder.inverse_transform([np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "20f32a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Anxiety'], dtype=object)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [\"My mind is always buzzing with thoughts, ideas, and distractions. It's hard to focus on one thing for too long, and I often feel restless, like I need to keep moving. Tasks that seem simple to others feel like mountains to me. I just want to feel in control\"]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_text)\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "predictions = model.predict(sample_padded)\n",
    "label_encoder.inverse_transform([np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1c02b2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Depression'], dtype=object)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [\"Even when I'm surrounded by people, I feel a deep sense of isolation. It's like there's an invisible wall between me and everyone else. I long for connection, for someone who truly understands, but it feels like no one really sees me. The emptiness is overwhelming\"]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_text)\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "predictions = model.predict(sample_padded)\n",
    "label_encoder.inverse_transform([np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4511a5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "935/935 [==============================] - 17s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_x_padded)\n",
    "y_pred = [np.argmax(x) for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ec05eb4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:\n",
      "0.8936170212765957\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88      1559\n",
      "           1       0.83      0.87      0.85      1170\n",
      "           2       0.90      0.87      0.89      6137\n",
      "           3       0.95      0.92      0.93      6452\n",
      "           4       0.69      0.90      0.78       512\n",
      "           5       0.70      0.82      0.75      1149\n",
      "           6       0.85      0.94      0.89      1681\n",
      "           7       0.96      0.90      0.93      6662\n",
      "           8       0.86      0.89      0.88      4570\n",
      "\n",
      "    accuracy                           0.89     29892\n",
      "   macro avg       0.84      0.89      0.86     29892\n",
      "weighted avg       0.90      0.89      0.89     29892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(test_y_encoded, y_pred))\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_y_encoded, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "db59408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('RNN model v3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6e38a266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Anxiety', 'Bipolar', 'Depression', 'Normal',\n",
       "       'Personality disorder', 'Stress', 'Suicidal'], dtype=object)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "acd19ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('RNN model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55a97aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Normal'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample_text = [df[df[\"status\"] == \"Personality disorder\"].iloc[88][\"cleaned_post\"]]\n",
    "sample_text = [\"I hate myself  my neighbour  everyone\"]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_text)\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "predictions = model.predict(sample_padded)\n",
    "label_encoder.inverse_transform([np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b9e502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b0e2d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67d5340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb5daa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1cd295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d78bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6ad6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b8f553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f0f873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be81ff41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feedeec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69658fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "4b68bc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_15 (Embedding)    (None, 100, 64)           320000    \n",
      "                                                                 \n",
      " conv1d_36 (Conv1D)          (None, 96, 256)           82176     \n",
      "                                                                 \n",
      " max_pooling1d_36 (MaxPoolin  (None, 48, 256)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 48, 256)           0         \n",
      "                                                                 \n",
      " conv1d_37 (Conv1D)          (None, 46, 128)           98432     \n",
      "                                                                 \n",
      " max_pooling1d_37 (MaxPoolin  (None, 23, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 23, 128)           0         \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 2944)              0         \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 2944)             11776     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 64)                188480    \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 701,319\n",
      "Trainable params: 695,431\n",
      "Non-trainable params: 5,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# Building a CNN model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=64, input_length=max_length),\n",
    "    \n",
    "    \n",
    "    # Convolutional layers with activation\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Conv1D(128, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    # Flatten the output to feed into dense layers\n",
    "    Flatten(),\n",
    "\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Dense(7, activation='softmax')  # Use softmax for multi-class classification\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a17051ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.70814961787184, 1: 2.3084065743085556, 2: 0.43114033460696666, 3: 0.4061700027084407, 4: 5.529796598073035, 5: 2.4883048760905635, 6: 1.620220959815983}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class_counts = np.array([7776, 5754, 30808, 32702, 2402, 5338, 8198])\n",
    "total_samples = np.sum(class_counts)\n",
    "num_classes = len(class_counts)\n",
    "class_weights = {i: total_samples / (num_classes * count) for i, count in enumerate(class_counts)}\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a2ba4a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "377/377 [==============================] - 8s 18ms/step - loss: 1.0934 - accuracy: 0.7196 - val_loss: 0.8840 - val_accuracy: 0.8243\n",
      "Epoch 2/10\n",
      "377/377 [==============================] - 7s 17ms/step - loss: 0.5591 - accuracy: 0.8598 - val_loss: 0.4532 - val_accuracy: 0.8837\n",
      "Epoch 3/10\n",
      "377/377 [==============================] - 7s 17ms/step - loss: 0.4662 - accuracy: 0.8892 - val_loss: 0.4135 - val_accuracy: 0.9036\n",
      "Epoch 4/10\n",
      "377/377 [==============================] - 7s 17ms/step - loss: 0.4137 - accuracy: 0.9077 - val_loss: 0.3962 - val_accuracy: 0.9119\n",
      "Epoch 5/10\n",
      "377/377 [==============================] - 7s 17ms/step - loss: 0.3681 - accuracy: 0.9217 - val_loss: 0.3557 - val_accuracy: 0.9242\n",
      "Epoch 6/10\n",
      "377/377 [==============================] - 7s 17ms/step - loss: 0.3376 - accuracy: 0.9309 - val_loss: 0.3290 - val_accuracy: 0.9327\n",
      "Epoch 7/10\n",
      "377/377 [==============================] - 7s 18ms/step - loss: 0.2990 - accuracy: 0.9416 - val_loss: 0.3288 - val_accuracy: 0.9356\n",
      "Epoch 8/10\n",
      "377/377 [==============================] - 7s 18ms/step - loss: 0.2807 - accuracy: 0.9474 - val_loss: 0.3153 - val_accuracy: 0.9391\n",
      "Epoch 9/10\n",
      "377/377 [==============================] - 7s 18ms/step - loss: 0.2624 - accuracy: 0.9530 - val_loss: 0.2814 - val_accuracy: 0.9510\n",
      "Epoch 10/10\n",
      "377/377 [==============================] - 7s 18ms/step - loss: 0.2419 - accuracy: 0.9581 - val_loss: 0.2881 - val_accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x_padded,\n",
    "                           train_y_encoded,\n",
    "                           epochs=10,\n",
    "                           batch_size=256,\n",
    "                           validation_data=(test_x_padded, test_y_encoded),\n",
    "#                            class_weight=class_weights,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "62bfb85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "754/754 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_x_padded)\n",
    "y_pred = [np.argmax(x) for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "71bf963f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:\n",
      "0.9500497429945283\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      1551\n",
      "           1       0.95      0.96      0.96      6174\n",
      "           2       0.95      0.98      0.96      6589\n",
      "           3       0.83      0.76      0.79       476\n",
      "           4       0.90      0.70      0.79      1086\n",
      "           5       0.95      0.96      0.95      1623\n",
      "           6       0.98      0.97      0.97      6625\n",
      "\n",
      "    accuracy                           0.95     24124\n",
      "   macro avg       0.92      0.89      0.91     24124\n",
      "weighted avg       0.95      0.95      0.95     24124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(test_y_encoded, y_pred))\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_y_encoded, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "50a8f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('CNN model v3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ffb493cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('CNN model v1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdfe8ac",
   "metadata": {},
   "source": [
    "# Anxiety "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8551bbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Anxiety'], dtype=object)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [\"Every day feels like a battle with my own thoughts. My heart races, and I feel a constant sense of dread. Even simple tasks feel overwhelming. I can't shake the fear that something terrible is about to happen, even when I know it's irrational. I just want peace.\"]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_text)\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "predictions = model.predict(sample_padded)\n",
    "label_encoder.inverse_transform([np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf06010",
   "metadata": {},
   "source": [
    "# adhd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "dc33e268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['adhd'], dtype=object)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [\"I had another day of impulsive decisions. I bought things I didn’t need and started projects I couldn’t finish. I want to have a plan, but sticking to one feels impossible. It’s exhausting to constantly fight against the urge to do a million things at once.\"]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_text)\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "predictions = model.predict(sample_padded)\n",
    "label_encoder.inverse_transform([np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce57568e",
   "metadata": {},
   "source": [
    "# Depression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "fd92ce6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Depression'], dtype=object)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [\"Today, like most days, I feel numb. There’s a heavy weight pressing down on me, making everything seem pointless. I’ve lost interest in things I used to love. Getting through the day feels like wading through thick mud. I just want to feel okay again.\"]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_text)\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "predictions = model.predict(sample_padded)\n",
    "label_encoder.inverse_transform([np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81788f70",
   "metadata": {},
   "source": [
    "# Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "774edbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Normal'], dtype=object)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [\"Woke up feeling refreshed today. Had a good breakfast and went for a walk in the park. Work was productive, and I felt good about my progress. Spent the evening watching a movie with friends. Nothing too special, but I enjoyed the day. Life feels steady right now.\"]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_text)\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "predictions = model.predict(sample_padded)\n",
    "label_encoder.inverse_transform([np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474a7d6c",
   "metadata": {},
   "source": [
    "# Personality Disorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c23146ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Normal'], dtype=object)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [\"I feel like I’m constantly at war with myself. My thoughts are chaotic, and I struggle to understand who I really am. My emotions change quickly, leaving me feeling unstable and disconnected from others. I crave relationships but often push people away without meaning to.\"]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_text)\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "predictions = model.predict(sample_padded)\n",
    "label_encoder.inverse_transform([np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89473f3d",
   "metadata": {},
   "source": [
    "# Stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "fcaf6034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Stress'], dtype=object)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [\"Today, my chest felt tight all day. I’m overwhelmed by all the things I have to do and not enough time to do them. My thoughts are scattered, and I can't focus on one task. I wish I could find a way to relax, but the stress is relentless.\"]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_text)\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "predictions = model.predict(sample_padded)\n",
    "label_encoder.inverse_transform([np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4d5e7e",
   "metadata": {},
   "source": [
    "# Addiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e6c59906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['addiction'], dtype=object)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [\"I tried to stay clean today, but the cravings were too strong. I feel trapped in a cycle that I can't escape. I know it’s hurting me, but I can't stop. Each time I use, I feel a momentary relief, followed by crushing guilt and shame.\"]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_text)\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "predictions = model.predict(sample_padded)\n",
    "label_encoder.inverse_transform([np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cfbac5",
   "metadata": {},
   "source": [
    "# 3 Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "9396a3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Normal'], dtype=object)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [\"Woke up feeling refreshed today. Had a good breakfast and went for a walk in the park. Work was productive, and I felt good about my progress. Spent the evening watching a movie with friends. Nothing too special, but I enjoyed the day. Life feels steady right now.\"]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_text)\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "predictions = model.predict(sample_padded)\n",
    "label_encoder.inverse_transform([np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "edf7a621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Normal'], dtype=object)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [\"Today was a typical day. Went through my routine at work, met all my deadlines. Came home, made dinner, and relaxed with a book. I’m feeling alright, just content. There’s a sense of calm in the ordinary. Sometimes, I wonder if I should be doing more.\"]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_text)\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "predictions = model.predict(sample_padded)\n",
    "label_encoder.inverse_transform([np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b0e8e018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Normal'], dtype=object)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [\"I spent the day doing a bit of everything—work, chores, a little bit of reading. It’s these kinds of days that remind me how nice it is to just have balance. Nothing extraordinary, but there’s comfort in routine. Life feels balanced, and I'm okay with that.\"]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_text)\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "predictions = model.predict(sample_padded)\n",
    "label_encoder.inverse_transform([np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e1796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
